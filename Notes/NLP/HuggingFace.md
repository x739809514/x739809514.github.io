## HuggingFace æ˜¯ä»€ä¹ˆ
Hugging Face æ˜¯ä¸€å®¶è‡´åŠ›äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æŠ€æœ¯çš„å…¬å¸ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸€ä¸ªå¹¿å—æ¬¢è¿çš„å¼€æºç¤¾åŒºå¹³å°ã€‚å®ƒæä¾›äº†å¤šç§å·¥å…·å’Œåº“ï¼Œå¸®åŠ©å¼€å‘è€…å’Œç ”ç©¶äººå‘˜æ„å»ºã€è®­ç»ƒå’Œéƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯ç”¨äºå¤„ç†æ–‡æœ¬æ•°æ®çš„æ¨¡å‹ã€‚
- **ğŸ¤— Transformers åº“**ï¼šè¿™æ˜¯ Hugging Face æœ€è‘—åçš„åº“ä¹‹ä¸€ï¼Œæä¾›äº†è®¸å¤šé¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼Œä¾‹å¦‚ BERTã€GPTã€T5 ç­‰ã€‚å®ƒä»¬å¯ä»¥ç”¨äºå„ç§ NLP ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€ç”Ÿæˆã€ç¿»è¯‘ã€é—®ç­”ç­‰ã€‚
- **ğŸ”§ Datasets åº“**ï¼šè¿™ä¸ªåº“æä¾›äº†å¤§é‡é¢„å¤„ç†å¥½çš„æ•°æ®é›†ï¼Œå¯ä»¥æ–¹ä¾¿åœ°ç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚å®ƒæ”¯æŒå¤šç§æ•°æ®æ ¼å¼ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾ä¸ Transformers åº“é›†æˆã€‚
- **ğŸ› ï¸ Tokenizers åº“**ï¼šç”¨äºå¤„ç†æ–‡æœ¬æ•°æ®çš„åˆ†è¯åº“ï¼Œæ”¯æŒå¿«é€Ÿå’Œé«˜æ•ˆçš„æ–‡æœ¬é¢„å¤„ç†ã€‚è¿™å¯¹äºå¤„ç†å¤§å‹æ•°æ®é›†éå¸¸æœ‰ç”¨ã€‚
- **ğŸ“¦ Model Hub**ï¼šHugging Face æä¾›äº†ä¸€ä¸ªæ¨¡å‹ä»“åº“ï¼Œç”¨æˆ·å¯ä»¥åœ¨ä¸Šé¢å‘å¸ƒå’Œåˆ†äº«ä»–ä»¬è®­ç»ƒçš„æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥ä»ä¸­ä¸‹è½½ä»–äººåˆ†äº«çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚è¿™ä¸ªä»“åº“åŒ…æ‹¬äº†å„ç§å„æ ·çš„æ¨¡å‹ï¼Œé€‚ç”¨äºä¸åŒçš„ä»»åŠ¡å’Œè¯­è¨€ã€‚
- **ğŸŒ Hub API**ï¼šHugging Face æä¾›äº†ä¸€ä¸ªç®€å•æ˜“ç”¨çš„ APIï¼Œå¯ä»¥ç›´æ¥åœ¨åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿›è¡Œæ¨ç†å’Œé¢„æµ‹ã€‚
- **ğŸ‘¥ ç¤¾åŒºå’Œæ”¯æŒ**ï¼šHugging Face æ‹¥æœ‰ä¸€ä¸ªæ´»è·ƒçš„ç¤¾åŒºï¼Œç”¨æˆ·å¯ä»¥åœ¨è®ºå›ã€GitHub å’Œå…¶ä»–å¹³å°ä¸Šäº’ç›¸äº¤æµå’Œåˆ†äº«ç»éªŒã€‚

### ä½¿ç”¨æ¡ˆä¾‹ï¼ˆä¸€ï¼‰

å®šä¹‰ä¸€ä¸ªtask,ç„¶åä»å¼€æºç¤¾åŒºä¸­æŠŠmodelçš„åå­—æ‹·è´ä¸‹æ¥ä½¿ç”¨
```python
#%% packages
from transformers import pipeline

# %% only provide task
pipe = pipeline(task="text-classification")
# %% run pipe
pipe("I like it very much.")
# %% provide model
pipe = pipeline(task="text-classification",
Â  Â  Â  Â  Â  Â  Â  Â  model="nlptown/bert-base-multilingual-uncased-sentiment")
# %% run pipe
# consume just a string
pipe("I like it very much.")
# %% consume a list
pipe(["I like it very much.", "I hate it."])
```
`pipeline` å‡½æ•°ä¼šæ ¹æ®ä½ æŒ‡å®šçš„ä»»åŠ¡è‡ªåŠ¨åŠ è½½åˆé€‚çš„é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨ã€‚ä½ åªéœ€æä¾›ä»»åŠ¡åç§°å’Œè¾“å…¥æ–‡æœ¬å³å¯ï¼Œè¿™é‡Œä½¿ç”¨pipelineåŠ è½½äº†ä¸€ä¸ªæƒ…æ„Ÿåˆ†æçš„æ¨¡å‹ï¼Œæœ€åä¼šé€šè¿‡starçš„ä¸ªæ•°æ¥è¡¨ç¤ºæƒ…æ„Ÿææ€§ã€‚
```
[{'label': '5 stars', 'score': 0.5000861883163452}]

[
{'label': '5 stars', 'score': 0.5000861883163452}, 
{'label': '1 star', 'score': 0.7190805077552795}
]
```

### ä½¿ç”¨æ¡ˆä¾‹ï¼ˆäºŒï¼‰

```python
#%% packages
from transformers import pipeline

# %% Named Entity Recognition
pipe = pipeline(task="ner")
pipe("Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne on April 1, 1976, in Cupertino, California.")
```
`ner`æ¨¡å‹å¯ä»¥å¯¹è¯æ€§è¿›è¡Œåˆ†ç±»
```
[{'entity': 'I-ORG',
  'score': 0.99959284,
  'index': 1,
  'word': 'Apple',
  'start': 0,
  'end': 5},
 {'entity': 'I-ORG',
  'score': 0.9994708,
  'index': 2,
  'word': 'Inc',
  'start': 6,
  'end': 9},
 {'entity': 'I-PER',
  'score': 0.9993297,
  'index': 7,
  'word': 'Steve',
  'start': 26,
  'end': 31},
 ......
 {'entity': 'I-LOC',
  'score': 0.998528,
  'index': 31,
  'word': 'California',
  'start': 102,
  'end': 112}]
```

### ä½¿ç”¨æ¡ˆä¾‹ï¼ˆä¸‰ï¼‰

```python
#%% packages
from transformers import pipeline

# %% Question Answering
pipe = pipeline("question-answering")
pipe(context="The Big Apple is a nickname for New York City.", question="What is the Big Apple?")
```
é—®ç­”æ¨¡å‹ï¼Œoutputï¼š
```
{
 'score': 0.6228488683700562,
 'start': 17,
 'end': 45,
 'answer': 'a nickname for New York City'
 }
```
## Zero-Shot Classification

Zero-shot classification æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œå®ƒå…è®¸æ¨¡å‹åœ¨æ²¡æœ‰é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå¯¹æœªè§è¿‡çš„ç±»åˆ«è¿›è¡Œåˆ†ç±»ã€‚è¿™ç§æ–¹æ³•ä¾èµ–äºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†æ–°ç±»åˆ«çš„è¾“å…¥ï¼Œå¹¶æ¨æ–­å‡ºè¾“å…¥ä¸è¿™äº›æ–°ç±»åˆ«çš„å…³ç³»ã€‚
### ä¸»è¦ç‰¹ç‚¹ï¼š

- **æ— éœ€ç‰¹å®šç±»åˆ«è®­ç»ƒ**: ä¼ ç»Ÿçš„åˆ†ç±»æ¨¡å‹éœ€è¦åœ¨è®­ç»ƒæ—¶æ˜ç¡®åœ°é’ˆå¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œå­¦ä¹ ï¼Œè€Œ zero-shot classification åˆ™ä¸éœ€è¦å¯¹ç‰¹å®šç±»åˆ«è¿›è¡Œè®­ç»ƒã€‚æ¨¡å‹é€šè¿‡ç†è§£ä»»åŠ¡çš„æè¿°æˆ–ç±»åˆ«çš„è¯­ä¹‰ä¿¡æ¯ï¼Œèƒ½å¤Ÿå¤„ç†æ–°çš„ç±»åˆ«ã€‚
- **çµæ´»æ€§**: ç”±äºæ¨¡å‹ä¸å±€é™äºé¢„å…ˆå®šä¹‰çš„ç±»åˆ«ï¼Œzero-shot classification æä¾›äº†æå¤§çš„çµæ´»æ€§ï¼Œé€‚ç”¨äºéœ€è¦åŠ¨æ€å¤„ç†ä¸åŒç±»åˆ«çš„åº”ç”¨åœºæ™¯ã€‚
### å·¥ä½œåŸç†ï¼š

Zero-shot classification çš„æ ¸å¿ƒåœ¨äºæ¨¡å‹å¦‚ä½•ç†è§£è¾“å…¥å’Œç±»åˆ«ä¹‹é—´çš„å…³ç³»ã€‚é€šå¸¸ï¼Œè¿™ç±»æ¨¡å‹ä¼šåˆ©ç”¨é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œå¦‚ BERTã€GPT ç­‰ï¼Œè¿™äº›æ¨¡å‹å…·å¤‡å¼ºå¤§çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚ä»¥ä¸‹æ˜¯é›¶æ ·æœ¬åˆ†ç±»çš„åŸºæœ¬å·¥ä½œæµç¨‹ï¼š
1. **è¾“å…¥æ–‡æœ¬**: ç”¨æˆ·æä¾›ä¸€ä¸ªæ–‡æœ¬æˆ–å¥å­ï¼Œæ¨¡å‹éœ€è¦å¯¹æ­¤è¿›è¡Œåˆ†ç±»ã€‚
2. **ç±»åˆ«æ ‡ç­¾**: ç”¨æˆ·æä¾›ä¸€ç»„ç±»åˆ«æ ‡ç­¾ï¼ˆå¯ä»¥æ˜¯å‡ ä¸ªå•è¯æˆ–ä¸€ä¸ªæè¿°æ€§çŸ­è¯­ï¼‰ï¼Œè¿™äº›ç±»åˆ«æ ‡ç­¾å¯èƒ½æ˜¯æ¨¡å‹åœ¨è®­ç»ƒä¸­æœªè§è¿‡çš„ã€‚
3. **è¯­ä¹‰åŒ¹é…**: æ¨¡å‹å°†è¾“å…¥æ–‡æœ¬ä¸æ¯ä¸ªç±»åˆ«æ ‡ç­¾è¿›è¡Œè¯­ä¹‰åŒ¹é…ï¼Œè®¡ç®—å®ƒä»¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚
4. **æ¦‚ç‡è¾“å‡º**: æ¨¡å‹è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒï¼Œè¡¨ç¤ºè¾“å…¥æ–‡æœ¬å±äºå„ä¸ªç±»åˆ«çš„å¯èƒ½æ€§ã€‚
```python
#%% packages
from transformers import pipeline
import pandas as pd

#%% Classifier
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
Â # %% Data Preparation
# first example: Raymond Chandler "The Big Sleep" (crime novel)
# second example: J.R.R. Tolkien "The Lord of the Rings" (fantasy novel)
# third example: Bill Bryson "A Short History of Nearly Everything"

documents = ["It was about eleven oâ€™clock in the morning, mid October, with the sun not shining and a look of hard wet rain in the clearness of the foothills. I was wearing my powder-blue suit, with dark blue shirt, tie and display handkerchief, black brogues, black wool socks with dark blue clocks on them. I was neat, clean, shaved and sober, and I didnâ€™t care who knew it. I was everything the well-dressed private detective ought to be. I was calling on four million dollars.",

Â  Â  Â  Â  Â  Â  Â "When Mr. Bilbo Baggins of Bag End announced that he would shortly be celebrating his eleventy-first birthday with a party of special magnificence, there was much talk and excitement in Hobbiton.",

Â  Â  Â  Â  Â  Â  Â "Welcome. And congratulations. I am delighted that you could make it. Getting here wasnâ€™t easy, I know. In fact, I suspect it was a little tougher than you realize. To begin with, for you to be here now trillions of drifting atoms had somehow to assemble in an intricate and curiously obliging manner to create you. Itâ€™s an arrangement so specialized and particular that it has never been tried before and will only exist this once."
Â  Â  Â  Â  Â  Â  Â ]

candidate_labels=["history", "crime", "fantasy"]

#%% classify documents, åŒæ—¶æŠŠå‚æ•°ä¹Ÿä¼ å…¥è¿›å»
res = classifier(documents, candidate_labels = candidate_labels)

#%% visualize results
pd.DataFrame(res[1]).plot.bar(x='labels', y='scores', title='Lord of the Rings')

# %% flag multiple labels
classifier(documents[0], candidate_labels = candidate_labels, multi_label=False)
```